{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":8759057,"datasetId":4097952,"databundleVersionId":8914297}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-23T17:28:47.965291Z","iopub.execute_input":"2024-06-23T17:28:47.965833Z","iopub.status.idle":"2024-06-23T17:28:49.033943Z","shell.execute_reply.started":"2024-06-23T17:28:47.965790Z","shell.execute_reply":"2024-06-23T17:28:49.032609Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/rbp-training-test/S_cerevisiae_RBP_nonRBP_Test.fasta\n/kaggle/input/rbp-training-test/A_thaliana_RBP_nonRBP_Test.fasta\n/kaggle/input/rbp-training-test/Human_RBP_nonRBP_Test.fasta\n/kaggle/input/rbp-training-test/capsgan.ipynb\n/kaggle/input/rbp-training-test/atten-bilstm-resg.ipynb\n/kaggle/input/rbp-training-test/RBP_nonRBP_Training.fasta\n/kaggle/input/rbp-training-test/feature-selection.ipynb\n/kaggle/input/rbp-training-test/DNA_RNA_binding_datasets/Non-NABP.fasta\n/kaggle/input/rbp-training-test/DNA_RNA_binding_datasets/RBP.fasta\n/kaggle/input/rbp-training-test/DNA_RNA_binding_datasets/DSB.fasta\n/kaggle/input/rbp-training-test/DNA_RNA_binding_datasets/SSB.fasta\n/kaggle/input/rbp-training-test/PSSM_features/edp.csv\n/kaggle/input/rbp-training-test/PSSM_features/k_separated_bigrams_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/pse_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/eedp.csv\n/kaggle/input/rbp-training-test/PSSM_features/d_fpssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/aac_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/aatp.csv\n/kaggle/input/rbp-training-test/PSSM_features/dpc_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/aadp_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/pssm_cc.csv\n/kaggle/input/rbp-training-test/PSSM_features/ab_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/medp.csv\n/kaggle/input/rbp-training-test/PSSM_features/dp_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/pssm_ac.csv\n/kaggle/input/rbp-training-test/PSSM_features/pssm_composition.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/edp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/k_separated_bigrams_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/pse_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/eedp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/d_fpssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/aac_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/aatp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/dpc_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/aadp_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/pssm_cc.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/ab_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/medp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/dp_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/A_thaliana_PSSM_Features/pssm_ac.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/edp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/k_separated_bigrams_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/pse_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/eedp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/d_fpssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/aac_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/aatp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/dpc_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/aadp_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/pssm_cc.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/ab_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/medp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/dp_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/S_cerevisiae_test_pssm/pssm_ac.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/edp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/k_separated_bigrams_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/pse_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/eedp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/d_fpssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/aac_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/aatp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/dpc_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/aadp_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/pssm_cc.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/ab_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/medp.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/dp_pssm.csv\n/kaggle/input/rbp-training-test/PSSM_features/RBP_test_pssm/Human_test_pssm/pssm_ac.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/S_cerevisiae/S_cerevisiae_Test_CTDC_CTDD_CTDT.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/S_cerevisiae/S_cerevisiae_Test_APAAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/S_cerevisiae/S_cerevisiae_Test_EAAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/S_cerevisiae/S_cerevisiae_Test_AAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/S_cerevisiae/S_cerevisiae_Test_PAAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/A_thaliana/A_thaliana_Test_APAAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/A_thaliana/A_thaliana_Test_CTD_CTDD_CTDT.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/A_thaliana/A_thaliana_Test_AAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/A_thaliana/A_thaliana_Test_PAAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/A_thaliana/A_thaliana_Test_EAAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/Human/Human_Test_CTDC_CTDD_CTDT.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/Human/Human_Test_EAAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/Human/Human_Test_PAAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/Human/Human_Test_APAAC.csv\n/kaggle/input/rbp-training-test/RBP_test_sequence_features/Human/Human_Test_AAC.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/ALBER_feature_test/A_thaliana_RBP_nonRBP_Test_prot_albert.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/ALBER_feature_test/Human_RBP_nonRBP_Test_prot_albert.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/ALBER_feature_test/S_cerevisiae_RBP_nonRBP_Test_prot_albert.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/ESM-2/A_thaliana_RBP_nonRBP_Test_ESM-2.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/ESM-2/S_cerevisiae_RBP_nonRBP_Test_ESM-2.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/ESM-2/Human_RBP_nonRBP_Test_ESM-2.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/ESM1b_test_features/esm1b_A_thaliana_RBP_nonRBP_Test.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/ESM1b_test_features/esm1b_Human_RBP_nonRBP_Test.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/ESM1b_test_features/esm1b_S_cerevisiae_RBP_nonRBP_Test.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/protbert_bfd_testing_features/protbert_bfd_Human_RBP_nonRBP.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/protbert_bfd_testing_features/protbert_bfd_S_cerevisiae_RBP_nonRBP.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/protbert_bfd_testing_features/protbert_bfd_A_thaliana.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/portT5_test_features/Human_protT5_test.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/portT5_test_features/A_thaliana_protT5.csv\n/kaggle/input/rbp-training-test/RBP_test_PLM_features/portT5_test_features/S_cerevisiae_protT5_test.csv\n/kaggle/input/rbp-training-test/RBP_training_PLM_features/RBP_ProtT5_features.csv\n/kaggle/input/rbp-training-test/RBP_training_PLM_features/RBP_Training_protbert_bfd_features.csv\n/kaggle/input/rbp-training-test/RBP_training_PLM_features/RBP_nonRBP_9873_ESM1b.csv\n/kaggle/input/rbp-training-test/RBP_training_PLM_features/RBP_Albert_prot_feature_train.csv\n/kaggle/input/rbp-training-test/RBP_training_PLM_features/RBP_non_RBP_9873_ESM-2.csv\n/kaggle/input/rbp-training-test/RBP_training_sequenctial_features/RBP_nonRBP_Training_PAAC.csv\n/kaggle/input/rbp-training-test/RBP_training_sequenctial_features/RBP_nonRBP_Training_APAAC.csv\n/kaggle/input/rbp-training-test/RBP_training_sequenctial_features/RBP_nonRBP_Training_EAAC.csv\n/kaggle/input/rbp-training-test/RBP_training_sequenctial_features/RBP_nonRBP_Training_CTDC_CTDD_CTDT.csv\n/kaggle/input/rbp-training-test/RBP_training_sequenctial_features/RBP_nonRBP_Training_AAC.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch==1.13.0\n!install tensorflow==2.8.0\n!pip install tensorflow==2.8.0","metadata":{"execution":{"iopub.status.busy":"2024-06-23T17:33:23.645613Z","iopub.execute_input":"2024-06-23T17:33:23.645982Z","iopub.status.idle":"2024-06-23T17:36:19.819773Z","shell.execute_reply.started":"2024-06-23T17:33:23.645954Z","shell.execute_reply":"2024-06-23T17:36:19.817471Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torch==1.13.0\n  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl.metadata (23 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.13.0) (4.9.0)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.0)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.0)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (69.0.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (0.42.0)\nDownloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2+cpu\n    Uninstalling torch-2.1.2+cpu:\n      Successfully uninstalled torch-2.1.2+cpu\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.1.2+cpu requires torch==2.1.2, but you have torch 1.13.0 which is incompatible.\ntorchdata 0.7.1 requires torch>=2, but you have torch 1.13.0 which is incompatible.\ntorchtext 0.16.2+cpu requires torch==2.1.2, but you have torch 1.13.0 which is incompatible.\ntorchvision 0.16.2+cpu requires torch==2.1.2, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0\ninstall: missing destination file operand after 'tensorflow==2.8.0'\nTry 'install --help' for more information.\nCollecting tensorflow==2.8.0\n  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (23.5.26)\nRequirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (3.10.0)\nCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0)\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (16.0.6)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (3.3.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (4.9.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.14.1)\nCollecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0)\n  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0)\n  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.60.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.26.1)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\nDownloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.8.0 which is incompatible.\ntensorflow-serving-api 2.14.1 requires tensorflow<3,>=2.14.1, but you have tensorflow 2.8.0 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.8.0 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport sys\nimport math\nimport numpy as np\nimport pandas as pd\nimport statistics\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import scale\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import initializers, regularizers, constraints\nfrom tensorflow.keras.activations import sigmoid\nfrom tensorflow.keras.layers import Input, Dense, Layer, Reshape, Flatten\nfrom tensorflow.keras.layers import multiply, Add, Permute\nfrom tensorflow.keras.layers import Dropout, Lambda, Concatenate, Multiply\nfrom tensorflow.keras.layers import BatchNormalization, Activation\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.optimizers import adam_v2\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.decomposition import PCA\n\n\n###########################\n#load the data\n\ndata_ = pd.read_csv(r'/kaggle/input/rbp-training-test/RBP_training_PLM_features/RBP_ProtT5_features.csv', header=None)\ndata = np.array(data_)\ndata = data[1:, 1:]\n[m1, n1] = np.shape(data)\nlabel1 = np.ones((int(2780), 1))\nlabel2 = np.zeros((int(7093), 1))\nlabels = np.append(label1, label2)\n\n# Split the data into training (80%) and testing (20%) sets\n# X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.2, random_state=42)\n\nX = data\ny = labels\n\n# Assuming X_train_whole = scale(X_train_whole)\n[sample_num, input_dimwx] = np.shape(X)\n\n# X = X_train\n# y = y_train\n# xt = X_test\n# yt = y_test\n\n\ndef get_shuffle(data, label):\n    index = np.arange(len(label))\n    np.random.shuffle(index)\n    return data[index], label[index]\n\nX, y = get_shuffle(X, y)\n\ndef scale_mean_var(input_arr, axis=0):\n    mean_ = np.mean(input_arr, axis=0)\n    scale_ = np.std(input_arr, axis=0)\n    output_arr = input_arr - mean_\n    mean_1 = output_arr.mean(axis=0)\n    if not np.allclose(mean_1, 0):\n        output_arr -= mean_1\n    scale_[scale_ == 0.0] = 1.0\n    output_arr /= scale_\n    mean_2 = output_arr.mean(axis=0)\n    if not np.allclose(mean_2, 0):\n        output_arr -= mean_2\n    return output_arr\n\n########################################################### Def Cbam\ndef channel_attention(input_feature, ratio=8):\n\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n\tchannel = input_feature.shape[channel_axis]\n\tshared_layer_one = Dense(channel//ratio,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t activation = 'relu',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\tshared_layer_two = Dense(channel,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\tavg_pool = GlobalAveragePooling2D()(input_feature)\n\tavg_pool = Reshape((1,1,channel))(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\tavg_pool = shared_layer_one(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n\tavg_pool = shared_layer_two(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\tmax_pool = GlobalMaxPooling2D()(input_feature)\n\tmax_pool = Reshape((1,1,channel))(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\tmax_pool = shared_layer_one(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n\tmax_pool = shared_layer_two(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\tcbam_feature = Add()([avg_pool,max_pool])\n\tcbam_feature = Activation('hard_sigmoid')(cbam_feature)\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\treturn multiply([input_feature, cbam_feature])\n\n\ndef spatial_attention(input_feature):\n\tkernel_size = 7\n\tif K.image_data_format() == \"channels_first\":\n\t\tchannel = input_feature.shape[1]\n\t\tcbam_feature = Permute((2,3,1))(input_feature)\n\telse:\n\t\tchannel = input_feature.shape[-1]\n\t\tcbam_feature = input_feature\n\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n\tassert avg_pool.shape[-1] == 1\n\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n\tassert max_pool.shape[-1] == 1\n\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n\tassert concat.shape[-1] == 2\n\tcbam_feature = Conv2D(filters = 1,\n\t\t\t\t\tkernel_size=kernel_size,\n\t\t\t\t\tactivation = 'hard_sigmoid',\n\t\t\t\t\tstrides=1,\n\t\t\t\t\tpadding='same',\n\t\t\t\t\tkernel_initializer='he_normal',\n\t\t\t\t\tuse_bias=False)(concat)\n\tassert cbam_feature.shape[-1] == 1\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\treturn multiply([input_feature, cbam_feature])\n\n\ndef cbam_block(cbam_feature,ratio=8):\n\tcbam_feature = channel_attention(cbam_feature, ratio)\n\tcbam_feature = spatial_attention(cbam_feature, )\n\treturn cbam_feature\n\n\n############################################## Def discriminator and generator\ndef squash(vectors, axis=-1):\n    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n    return scale * vectors\n\ndef build_discriminator():\n    img = Input(shape=(1,input_dimwx,1))\n    x = Conv2D(filters=64, kernel_size=(1,9), strides=2, padding='valid', name='conv1')(img)\n    x = LeakyReLU()(x)\n    x = BatchNormalization(momentum=0.8)(x)\n\n    x = Conv2D(filters=32, kernel_size=(1,9), strides=2, padding='valid', name='conv1')(img)\n    x = LeakyReLU()(x)\n    x = BatchNormalization(momentum=0.8)(x)\n\n    \"\"\"\n    NOTE: Capsule architecture starts from here.\n    \"\"\"\n    ##### primarycaps coming first #####\n    x = Conv2D(filters=32, kernel_size=(1,3), strides=2, padding='valid', name='primarycap_conv2')(x)\n    [aa,bb,cc,dd] = x.shape\n    numx = int(cc)\n    x = Reshape(target_shape=[-1, numx], name='primarycap_reshape')(x)\n    x = Lambda(squash, name='primarycap_squash')(x)\n    x = BatchNormalization(momentum=0.8)(x)\n\n    ##### digitcaps are here #####\n    x = Flatten()(x)\n    uhat = Dense(128, kernel_initializer='he_normal', bias_initializer='zeros', name='uhat_digitcaps')(x)\n    c = Activation('softmax', name='softmax_digitcaps1')(uhat) # softmax will make sure that each weight c_ij is a non-negative number and their sum equals to one\n    c = Dense(128)(c) # compute s_j\n    x = Multiply()([uhat, c])\n    \"\"\"\n    NOTE: Squashing the capsule outputs creates severe blurry artifacts, thus we replace it with Leaky ReLu.\n    \"\"\"\n    s_j = LeakyReLU()(x)\n    ##### we will repeat the routing part 2 more times (num_routing=3) to unfold the loop\n    c = Activation('softmax', name='softmax_digitcaps2')(s_j) # softmax will make sure that each weight c_ij is a non-negative number and their sum equals to one\n    c = Dense(128)(c) # compute s_j\n    x = Multiply()([uhat, c])\n    s_j = LeakyReLU()(x)\n\n    c = Activation('softmax', name='softmax_digitcaps3')(s_j) # softmax will make sure that each weight c_ij is a non-negative number and their sum equals to one\n    c = Dense(128)(c) # compute s_j\n    x = Multiply()([uhat, c])\n    s_j = LeakyReLU()(x)\n\n    c = Activation('softmax', name='softmax_digitcaps4')(s_j) # softmax will make sure that each weight c_ij is a non-negative number and their sum equals to one\n    c = Dense(128)(c) # compute s_j\n    x = Multiply()([uhat, c])\n    s_j = LeakyReLU()(x)\n    # ##### preparition for cbam_block\n    s_j = Reshape((-1,128,1))(s_j)\n    inputs = s_j\n    residual = Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same', name='convxxx')(inputs)\n    residual = BatchNormalization(momentum=0.8)(residual)\n\n    cbam = cbam_block(residual)\n    # cbam = channel_attention(residual)\n    # cbam = spatial_attention(residual)\n\n    cbam = Reshape((-1,))(cbam)\n    pred = Dense(2, activation='sigmoid')(cbam)\n\n    # cbam = Reshape((-1,))(s_j)\n    # pred = Dense(2, activation='sigmoid')(cbam)\n\n\n    return Model(img, pred)\n\ndiscriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['binary_accuracy'])\n\n\n# generator structure\ndef build_generator():\n    \"\"\"\n    Generator follows the DCGAN architecture and creates generated image representations through learning.\n    \"\"\"\n    noise_shape =(input_dimwx,)\n    x_noise = Input(shape=noise_shape)\n    # we apply different kernel sizes in order to match the original image size\n    x = Dense(64 * 1 * input_dimwx, activation=\"relu\")(x_noise)\n    x = Reshape((1, input_dimwx, 64))(x)\n    x = BatchNormalization(momentum=0.2)(x)\n    x = UpSampling2D()(x)\n    [aa1,bb1,cc1,dd1] = x.shape\n    numx1 = int(cc1//4)\n    x = Conv2D(32, kernel_size=(2,numx1), padding=\"valid\")(x)\n    x = Activation(\"relu\")(x)\n    x = BatchNormalization(momentum=0.2)(x)\n    [aa2,bb2,cc2,dd2] = x.shape\n    #### x = UpSampling2D()(x)\n    numx2 = int(1+cc2-input_dimwx)\n    x = Conv2D(16, kernel_size=(1,numx2), padding=\"valid\")(x)\n    x = Activation(\"relu\")(x)\n    x = BatchNormalization(momentum=0.2)(x)\n    x = Conv2D(1, kernel_size=3, padding=\"same\")(x)\n    gen_out = Activation(\"tanh\")(x)\n\n    return Model(x_noise, gen_out)\n\ngenerator = build_generator()\ngenerator.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(0.002, 0.8), metrics=['binary_accuracy'])\n\n# feeding noise to generator\nz = Input(shape=(input_dimwx,))\nimg = generator(z)\n# for the combined model we will only train the generator\ndiscriminator.trainable = False\n# try to discriminate generated images\nvalid = discriminator(img)\n# the combined model (stacked generator and discriminator) takes\n# noise as input => generates images => determines validity\ncombined = Model(z, valid)\ncombined.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(0.002, 0.8), metrics=['binary_accuracy'])\n#########################################################\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n\n\ndef categorical_probas_to_classes(p):\n    return np.argmax(p, axis=1)\n\ndef to_categorical(y, nb_classes=None):\n    y = np.array(y, dtype='int')\n    if not nb_classes:\n        nb_classes = np.max(y) + 1\n    Y = np.zeros((len(y), nb_classes))\n    for i in range(len(y)):\n        Y[i, y[i]] = 1\n    return Y\n\nBACC_collecton = []\nSn_collecton = []\nSp_collecton = []\nMCC_collecton = []\nAUC_collecton = []\nAP = []\n\nmean_recall = np.linspace(0, 1, 100)\nall_precision = []\nbase_fpr = np.linspace(0, 1, 100)\nmean_tpr = 0.0\ninterp_tpr_collection = []\n\n# Define the directory to save the models\nsave_dir = '/kaggle/working/models/'\n\nskf = StratifiedKFold(n_splits=10)\nfor fold, (train, test) in enumerate(skf.split(X, y)):\n    X_train, X_valid, y_train, y_valid = X[train], X[test], y[train], y[test]\n    y_train = to_categorical(y_train)\n\n    # Reinitialize and compile models for each fold\n    discriminator = build_discriminator()\n    discriminator.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['binary_accuracy'])\n\n    generator = build_generator()\n    generator.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(0.002, 0.8), metrics=['binary_accuracy'])\n\n    z = Input(shape=(input_dimwx,))\n    img = generator(z)\n    discriminator.trainable = False\n    valid = discriminator(img)\n    combined = Model(z, valid)\n    combined.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(0.002, 0.8), metrics=['binary_accuracy'])\n\n    # Define checkpoint callback to save the best model\n    model_checkpoint = ModelCheckpoint(os.path.join(save_dir, f'model_fold_{fold+1}.h5'),\n                                       save_best_only=True,\n                                       monitor='val_loss',\n                                       mode='min')\n\n#     hist = combined.fit(X_train, y_train, batch_size=128, epochs=30, validation_data=(X_valid, to_categorical(y_valid)), callbacks=[model_checkpoint])\n    \n    \n\n    hist = combined.fit(X_train, y_train, batch_size=128, epochs=30, validation_data=(X_valid, to_categorical(y_valid)), \n                    callbacks=[model_checkpoint, early_stopping, reduce_lr])\n    # Load best model\n    # combined.load_weights(f'/content/drive/MyDrive/QSAR/models/model_fold_{fold+1}.h5')\n\n    y_score = combined.predict(X_valid)\n    y_class = categorical_probas_to_classes(y_score)\n\n    TP, FP, FN, TN = confusion_matrix(y_valid, y_class).ravel()\n    Sn_collecton.append(TP/(TP+FN))\n    Sp_collecton.append(TN/(TN+FP))\n    MCC = (TP*TN - FP*FN) / math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n    MCC_collecton.append(MCC)\n    BACC_collecton.append(0.5*TP/(TP+FN) + 0.5*TN/(TN+FP))\n\n    fpr, tpr, _ = roc_curve(y_valid, y_score[:, 1])\n    interp_tpr = np.interp(base_fpr, fpr, tpr)\n    interp_tpr[0] = 0.0\n    interp_tpr_collection.append(interp_tpr)\n    auc_roc = auc(fpr, tpr)\n    AUC_collecton.append(auc_roc)\n\n    precision, recall, _ = precision_recall_curve(y_valid, y_score[:, 1])\n    average_precision = average_precision_score(y_valid, y_score[:, 1])\n    recall = np.flipud(recall)\n    precision = np.flipud(precision)\n\n    mean_precision = np.interp(mean_recall, recall, precision)\n    all_precision.append(mean_precision)\n    AP.append(average_precision)\n    # Save the trained models\n    generator.save(os.path.join(save_dir, f'generator_model_fold_{fold+1}.h5'))\n    discriminator.save(os.path.join(save_dir, f'discriminator_model_fold_{fold+1}.h5'))\n\nprint(f'Balanced Accuracy: {np.mean(BACC_collecton):.3f} ± {np.std(BACC_collecton):.3f}')\nprint(f'Sensitivity: {np.mean(Sn_collecton):.3f} ± {np.std(Sn_collecton):.3f}')\nprint(f'Specificity: {np.mean(Sp_collecton):.3f} ± {np.std(Sp_collecton):.3f}')\nprint(f'MCC: {np.mean(MCC_collecton):.3f} ± {np.std(MCC_collecton):.3f}')\nprint(f'AUC: {np.mean(AUC_collecton):.3f} ± {np.std(AUC_collecton):.3f}')\nprint(f'Average Precision: {np.mean(AP):.3f} ± {np.std(AP):.3f}')\n\nmean_tpr = np.mean(interp_tpr_collection, axis=0)\nmean_tpr[-1] = 1.0\n\nmean_precision = np.mean(all_precision, axis=0)\n\nnp.savez('ROC_curve.npz', fpr=base_fpr, tpr=mean_tpr, roc_auc=AUC_collecton)\nnp.savez('PR_curve.npz', recall=mean_recall, precision=mean_precision, average_precision=AP)\n\nplt.figure()\nplt.plot(base_fpr, mean_tpr, color='darkorange', lw=2, label=f'ROC curve (area = {np.mean(AUC_collecton):.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('10-fold Cross-Validation ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport math\nimport numpy as np\nimport pandas as pd\nimport statistics\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import scale\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import initializers, regularizers, constraints\nfrom tensorflow.keras.activations import sigmoid\nfrom tensorflow.keras.layers import Input, Dense, Layer, Reshape, Flatten\nfrom tensorflow.keras.layers import multiply, Add, Permute\nfrom tensorflow.keras.layers import Dropout, Lambda, Concatenate, Multiply\nfrom tensorflow.keras.layers import BatchNormalization, Activation\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import load_model\nfrom keras.optimizers import adam_v2\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nBiLSTM=pd.read_csv(r'/kaggle/input/qsar-model/all_BiLSTM_train_2D.csv',header=None)\n\nAttention = pd.read_csv(r'/kaggle/input/qsar-model/all_atten_train_2D.csv',header=None)\n\ndataset = np.column_stack((BiLSTM, Attention))\n\ndata_train=np.array(dataset)\ndata_train=data_train[:1106,:]\n[m1,n1]=np.shape(data_train)\n# label1=np.ones((int(598),1))#Value can be changed\n# label2=np.zeros((int(508 ),1))\nlabel1=np.ones((598,1))#Value can be changed\nlabel2=np.zeros((508,1))\nlabel=np.append(label1,label2)\nshu=scale(data_train)\n\n# Split the data into training (80%) and testing (20%) sets\nX_train, X_test, y_train, y_test = train_test_split(shu, label, test_size=0.2, random_state=42)\n\nX_ind_test = xt\n# X_independent = shu.reshape(m1, n1, 1)\n# Xt=np.reshape(test_data,(-1,1,n1))\ny_ind_test = yt\n\n# Scale the independent data using the same scaling method as the training data\ndef scale_mean_var(input_arr, axis=0):\n    mean_ = np.mean(input_arr, axis=0)\n    scale_ = np.std(input_arr, axis=0)\n    output_arr = input_arr - mean_\n    mean_1 = output_arr.mean(axis=0)\n    if not np.allclose(mean_1, 0):\n        output_arr -= mean_1\n    scale_[scale_ == 0.0] = 1.0\n    output_arr /= scale_\n    mean_2 = output_arr.mean(axis=0)\n    if not np.allclose(mean_2, 0):\n        output_arr -= mean_2\n    return output_arr\n\n# Scale the independent test data\nX_ind_test_scaled = scale_mean_var(X_ind_test)\n\n# Load the pre-trained model\ndiscriminator = load_model('/kaggle/working/models/discriminator_model_fold_2.h5')\ngenerator = load_model('/kaggle/working/models/generator_model_fold_2.h5')\n\n# Build the combined model\nz = Input(shape=(X_ind_test_scaled.shape[1],))\nimg = generator(z)\ndiscriminator.trainable = False\nvalid = discriminator(img)\ncombined = Model(z, valid)\ncombined.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n\n# Evaluate the model on the independent test data\ny_ind_test_categorical = to_categorical(y_ind_test)\ny_score = combined.predict(X_ind_test_scaled)\ny_class = np.argmax(y_score, axis=1)\n\n# Calculate metrics\nTP, FP, FN, TN = confusion_matrix(y_ind_test, y_class).ravel()\nSn = TP / (TP + FN)\nSp = TN / (TN + FP)\nMCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\nBACC = 0.5 * Sn + 0.5 * Sp\n\n# ROC curve\nfpr, tpr, _ = roc_curve(y_ind_test, y_score[:, 1])\nroc_auc = auc(fpr, tpr)\n\n# PR curve\nprecision, recall, _ = precision_recall_curve(y_ind_test, y_score[:, 1])\naverage_precision = average_precision_score(y_ind_test, y_score[:, 1])\n\n# Output results\nprint(f\"BACC: {BACC:.3f}\")\nprint(f\"Sn: {Sn:.3f}\")\nprint(f\"Sp: {Sp:.3f}\")\nprint(f\"MCC: {MCC:.3f}\")\nprint(f\"AUC: {roc_auc:.3f}\")\nprint(f\"Average Precision: {average_precision:.3f}\")\n\n# Plot ROC curve\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve on Independent Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Plot PR curve\nplt.figure()\nplt.step(recall, precision, where='post', color='b', alpha=0.2, label='Average precision (area = %0.2f)' % average_precision)\nplt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve on Independent Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport math\nimport numpy as np\nimport pandas as pd\nimport statistics\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import scale\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import Input, Model\n\n# Load datasets\nBiLSTM = pd.read_csv(r'/kaggle/input/qsar-model/all_BiLSTM_train_2D.csv', header=None)\nAttention = pd.read_csv(r'/kaggle/input/qsar-model/all_atten_train_2D.csv', header=None)\ndataset = np.column_stack((BiLSTM, Attention))\n\n# Prepare training data\ndata_train = np.array(dataset)[:1106, :]\nlabel1 = np.ones((598, 1))  # Value can be changed\nlabel2 = np.zeros((508, 1))\nlabel = np.append(label1, label2)\nshu = scale(data_train)\n\n# Split the data into training (80%) and testing (20%) sets\nX_train, X_test, y_train, y_test = train_test_split(shu, label, test_size=0.2, random_state=42)\n\n# Independent test data (Assuming xt and yt are predefined)\nX_ind_test = xt\ny_ind_test = yt\n\n# Scale the independent data using the same scaling method as the training data\ndef scale_mean_var(input_arr, axis=0):\n    mean_ = np.mean(input_arr, axis=0)\n    scale_ = np.std(input_arr, axis=0)\n    output_arr = input_arr - mean_\n    mean_1 = output_arr.mean(axis=0)\n    if not np.allclose(mean_1, 0):\n        output_arr -= mean_1\n    scale_[scale_ == 0.0] = 1.0\n    output_arr /= scale_\n    mean_2 = output_arr.mean(axis=0)\n    if not np.allclose(mean_2, 0):\n        output_arr -= mean_2\n    return output_arr\n\n# Scale the independent test data\nX_ind_test_scaled = scale_mean_var(X_ind_test)\n\n# List of model filenames\nmodel_files = [f'/kaggle/working/models/discriminator_model_fold_{i}.h5' for i in range(1, 10)]\ngenerator_files = [f'/kaggle/working/models/generator_model_fold_{i}.h5' for i in range(1, 10)]\n\n# Loop through the models and evaluate each\nfor i, (discriminator_file, generator_file) in enumerate(zip(model_files, generator_files)):\n    print(f\"Evaluating model {i+1}/{len(model_files)}\")\n\n    # Load the pre-trained models\n    discriminator = load_model(discriminator_file)\n    generator = load_model(generator_file)\n\n    # Build the combined model\n    z = Input(shape=(X_ind_test_scaled.shape[1],))\n    img = generator(z)\n    discriminator.trainable = False\n    valid = discriminator(img)\n    combined = Model(z, valid)\n    combined.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n\n    # Evaluate the model on the independent test data\n    y_ind_test_categorical = to_categorical(y_ind_test)\n    y_score = combined.predict(X_ind_test_scaled)\n    y_class = np.argmax(y_score, axis=1)\n\n    # Calculate metrics\n    TP, FP, FN, TN = confusion_matrix(y_ind_test, y_class).ravel()\n    Sn = TP / (TP + FN)\n    Sp = TN / (TN + FP)\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n    BACC = 0.5 * Sn + 0.5 * Sp\n\n    # ROC curve\n    fpr, tpr, _ = roc_curve(y_ind_test, y_score[:, 1])\n    roc_auc = auc(fpr, tpr)\n\n    # PR curve\n    precision, recall, _ = precision_recall_curve(y_ind_test, y_score[:, 1])\n    average_precision = average_precision_score(y_ind_test, y_score[:, 1])\n\n    # Output results\n    print(f\"BACC: {BACC:.3f}\")\n    print(f\"Sn: {Sn:.3f}\")\n    print(f\"Sp: {Sp:.3f}\")\n    print(f\"MCC: {MCC:.3f}\")\n    print(f\"AUC: {roc_auc:.3f}\")\n    print(f\"Average Precision: {average_precision:.3f}\")\n\n    # Plot ROC curve\n    plt.figure()\n    lw = 2\n    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'ROC Curve on Independent Data for Model {i+1}')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    # Plot PR curve\n    plt.figure()\n    plt.step(recall, precision, where='post', color='b', alpha=0.2, label='Average precision (area = %0.2f)' % average_precision)\n    plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title(f'Precision-Recall Curve on Independent Data for Model {i+1}')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n","metadata":{},"execution_count":null,"outputs":[]}]}