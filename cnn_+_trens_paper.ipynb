{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0218bcf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:27.240339Z",
     "iopub.status.busy": "2024-06-28T07:53:27.239638Z",
     "iopub.status.idle": "2024-06-28T07:53:27.916961Z",
     "shell.execute_reply": "2024-06-28T07:53:27.916080Z"
    },
    "id": "arwnxlVCG7Dk",
    "papermill": {
     "duration": 0.691357,
     "end_time": "2024-06-28T07:53:27.919334",
     "exception": false,
     "start_time": "2024-06-28T07:53:27.227977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df535032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:27.940525Z",
     "iopub.status.busy": "2024-06-28T07:53:27.940110Z",
     "iopub.status.idle": "2024-06-28T07:53:27.944177Z",
     "shell.execute_reply": "2024-06-28T07:53:27.943367Z"
    },
    "id": "etwfoCm4FzJD",
    "outputId": "065aa862-131c-4bc9-a43c-5fb61f535fae",
    "papermill": {
     "duration": 0.016498,
     "end_time": "2024-06-28T07:53:27.946106",
     "exception": false,
     "start_time": "2024-06-28T07:53:27.929608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4980b618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:27.966425Z",
     "iopub.status.busy": "2024-06-28T07:53:27.966122Z",
     "iopub.status.idle": "2024-06-28T07:53:28.001915Z",
     "shell.execute_reply": "2024-06-28T07:53:28.001083Z"
    },
    "id": "55BKZYkHGyLq",
    "papermill": {
     "duration": 0.048011,
     "end_time": "2024-06-28T07:53:28.003820",
     "exception": false,
     "start_time": "2024-06-28T07:53:27.955809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnnamp_model = pd.read_csv('/kaggle/input/hemolytic/combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49ef86b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:28.024543Z",
     "iopub.status.busy": "2024-06-28T07:53:28.024061Z",
     "iopub.status.idle": "2024-06-28T07:53:28.030893Z",
     "shell.execute_reply": "2024-06-28T07:53:28.030105Z"
    },
    "id": "xBIFhP4-HHpR",
    "papermill": {
     "duration": 0.01914,
     "end_time": "2024-06-28T07:53:28.032801",
     "exception": false,
     "start_time": "2024-06-28T07:53:28.013661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=rnnamp_model['text']\n",
    "y=np.array(rnnamp_model['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a415019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:28.053723Z",
     "iopub.status.busy": "2024-06-28T07:53:28.053472Z",
     "iopub.status.idle": "2024-06-28T07:53:39.693802Z",
     "shell.execute_reply": "2024-06-28T07:53:39.692837Z"
    },
    "id": "9XWOVLm3IWdM",
    "papermill": {
     "duration": 11.653558,
     "end_time": "2024-06-28T07:53:39.696121",
     "exception": false,
     "start_time": "2024-06-28T07:53:28.042563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.saving import register_keras_serializable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a3cb9",
   "metadata": {
    "id": "2q-aMhFDM1fe",
    "papermill": {
     "duration": 0.009725,
     "end_time": "2024-06-28T07:53:39.716328",
     "exception": false,
     "start_time": "2024-06-28T07:53:39.706603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "109cd148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:39.737714Z",
     "iopub.status.busy": "2024-06-28T07:53:39.737154Z",
     "iopub.status.idle": "2024-06-28T07:53:39.746322Z",
     "shell.execute_reply": "2024-06-28T07:53:39.745606Z"
    },
    "id": "uv9R2gGqdiEV",
    "papermill": {
     "duration": 0.022116,
     "end_time": "2024-06-28T07:53:39.748151",
     "exception": false,
     "start_time": "2024-06-28T07:53:39.726035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd36feb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:39.768699Z",
     "iopub.status.busy": "2024-06-28T07:53:39.768426Z",
     "iopub.status.idle": "2024-06-28T07:53:39.775268Z",
     "shell.execute_reply": "2024-06-28T07:53:39.774514Z"
    },
    "id": "HWE99tR1ITF-",
    "outputId": "0f520fa4-bf67-4292-df5e-2efb2646541a",
    "papermill": {
     "duration": 0.019279,
     "end_time": "2024-06-28T07:53:39.777141",
     "exception": false,
     "start_time": "2024-06-28T07:53:39.757862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Example data\\ntexts = X_train\\n\\n# Tokenize the texts\\ntokenizer = Tokenizer()\\ntokenizer.fit_on_texts(texts)\\n\\n# Convert text to sequences of integers\\nsequences = tokenizer.texts_to_sequences(texts)\\ntest_seq=tokenizer.texts_to_sequences(X_test)\\n# Pad sequences to a fixed length\\nmaxlen = 100  # Adjust as needed based on your data\\npadded_sequences = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\\ntest=pad_sequences(test_seq, maxlen=maxlen, padding='post', truncating='post')\\n# Convert to NumPy array\\nX_train = tf.constant(padded_sequences)\\nX_test = tf.constant(test)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Example data\n",
    "texts = X_train\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "test_seq=tokenizer.texts_to_sequences(X_test)\n",
    "# Pad sequences to a fixed length\n",
    "maxlen = 100  # Adjust as needed based on your data\n",
    "padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "test=pad_sequences(test_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "# Convert to NumPy array\n",
    "X_train = tf.constant(padded_sequences)\n",
    "X_test = tf.constant(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d69b146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:39.798017Z",
     "iopub.status.busy": "2024-06-28T07:53:39.797774Z",
     "iopub.status.idle": "2024-06-28T07:53:39.801862Z",
     "shell.execute_reply": "2024-06-28T07:53:39.801039Z"
    },
    "id": "-QBDWhJ3zRp7",
    "papermill": {
     "duration": 0.016712,
     "end_time": "2024-06-28T07:53:39.803681",
     "exception": false,
     "start_time": "2024-06-28T07:53:39.786969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b9a9fa",
   "metadata": {
    "id": "KUctT5aQzjYs",
    "papermill": {
     "duration": 0.009784,
     "end_time": "2024-06-28T07:53:39.824610",
     "exception": false,
     "start_time": "2024-06-28T07:53:39.814826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58505871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:39.845724Z",
     "iopub.status.busy": "2024-06-28T07:53:39.845445Z",
     "iopub.status.idle": "2024-06-28T07:53:42.128358Z",
     "shell.execute_reply": "2024-06-28T07:53:42.127366Z"
    },
    "id": "CssLBsIAfRtH",
    "papermill": {
     "duration": 2.295732,
     "end_time": "2024-06-28T07:53:42.130596",
     "exception": false,
     "start_time": "2024-06-28T07:53:39.834864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizer(text,max_len):\n",
    "  #dic={'A':1,'G':1,'V':1,'I':2,'L':2,'F':2,'P':2,'Y':3,'M':3,'T':3,'S':3,'H':4,'N':4,'Q':4,'W':4,'K':5,'R':5,'D':6,'E':6,'C':7}\n",
    "  dic={'A':1,'G':2,'V':3,'I':4,'L':5,'F':6,'P':7,'Y':8,'M':9,'T':10,'S':11,'H':12,'N':13,'Q':14,'W':15,'K':16,'R':17,'D':18,'E':19,'C':20}\n",
    "  onehot=[]\n",
    "  t=[]\n",
    "  for i in range(len(text)):\n",
    "    row=[]\n",
    "    l=[]\n",
    "    char=text[i].split(' ')\n",
    "    for j in range(max_len):\n",
    "      if j< len(char):\n",
    "        row.append(dic[char[j]])\n",
    "        r=np.zeros(20)\n",
    "        r[dic[char[j]]-1]=1\n",
    "      else:\n",
    "        r=np.ones(20)*-1\n",
    "        row.append(0)\n",
    "      l.append(r)\n",
    "    l=np.array(l)\n",
    "    onehot.append(l)\n",
    "    t.append(row)\n",
    "  onehot=np.array(onehot)\n",
    "  t=np.array(t)\n",
    "  return t,onehot\n",
    "max_len=50\n",
    "X_train,onehot_train=tokenizer(X_train,max_len)\n",
    "X_test,onehot_test=tokenizer(X_test,max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fb64f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:42.152353Z",
     "iopub.status.busy": "2024-06-28T07:53:42.152000Z",
     "iopub.status.idle": "2024-06-28T07:53:42.158766Z",
     "shell.execute_reply": "2024-06-28T07:53:42.157897Z"
    },
    "id": "78cDRMz5-8j2",
    "papermill": {
     "duration": 0.019795,
     "end_time": "2024-06-28T07:53:42.160795",
     "exception": false,
     "start_time": "2024-06-28T07:53:42.141000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d):\n",
    "\n",
    "    # initialize a matrix angle_rads of all the angles\n",
    "    pos=np.arange(positions)[:, np.newaxis] #Column vector containing the position span [0,1,..., positions]\n",
    "    k= np.arange(d)[np.newaxis, :]  #Row vector containing the dimension span [[0, 1, ..., d-1]]\n",
    "    i = k//2\n",
    "    angle_rads = pos/(10000**(2*i/d)) #Matrix of angles indexed by (pos,i)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    #adds batch axis\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb9dd0",
   "metadata": {
    "id": "TyGqUBPEpfxg",
    "papermill": {
     "duration": 0.00972,
     "end_time": "2024-06-28T07:53:42.180483",
     "exception": false,
     "start_time": "2024-06-28T07:53:42.170763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a11b2cb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:53:42.201504Z",
     "iopub.status.busy": "2024-06-28T07:53:42.201230Z",
     "iopub.status.idle": "2024-06-28T07:55:18.977415Z",
     "shell.execute_reply": "2024-06-28T07:55:18.976321Z"
    },
    "id": "cXObcCXqFiGy",
    "outputId": "03866393-b8b1-43e0-e0af-80078cd004fb",
    "papermill": {
     "duration": 96.789165,
     "end_time": "2024-06-28T07:55:18.979592",
     "exception": false,
     "start_time": "2024-06-28T07:53:42.190427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "162/162 [==============================] - 17s 41ms/step - loss: 0.4569 - accuracy: 0.7860 - val_loss: 0.3550 - val_accuracy: 0.8591\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.3097 - accuracy: 0.8657 - val_loss: 0.3453 - val_accuracy: 0.8678\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.2518 - accuracy: 0.8980 - val_loss: 0.3063 - val_accuracy: 0.8817\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.2073 - accuracy: 0.9164 - val_loss: 0.3002 - val_accuracy: 0.8939\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.1688 - accuracy: 0.9319 - val_loss: 0.3786 - val_accuracy: 0.8435\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.1431 - accuracy: 0.9447 - val_loss: 0.3397 - val_accuracy: 0.8800\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.1191 - accuracy: 0.9557 - val_loss: 0.3390 - val_accuracy: 0.8835\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.0999 - accuracy: 0.9658 - val_loss: 0.3371 - val_accuracy: 0.8957\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.1016 - accuracy: 0.9599 - val_loss: 0.3587 - val_accuracy: 0.8887\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.0819 - accuracy: 0.9694 - val_loss: 0.3768 - val_accuracy: 0.8922\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.0776 - accuracy: 0.9712 - val_loss: 0.3616 - val_accuracy: 0.8991\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.0594 - accuracy: 0.9793 - val_loss: 0.3821 - val_accuracy: 0.8939\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.0579 - accuracy: 0.9789 - val_loss: 0.4341 - val_accuracy: 0.8939\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.0537 - accuracy: 0.9807 - val_loss: 0.4110 - val_accuracy: 0.8904\n"
     ]
    }
   ],
   "source": [
    "@register_keras_serializable()\n",
    "class TransformerModel(keras.Model):\n",
    "    def __init__(self, input_vocab_size, d_model, num_heads, ff_dim, rate=0.1, maxlen=50):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = layers.Embedding(input_vocab_size, d_model)\n",
    "        self.PE = positional_encoding(maxlen, d_model)\n",
    "        self.transformer_block = TransformerBlock_Encode(d_model, num_heads, ff_dim, rate)\n",
    "        self.transformer_block2 = TransformerBlock_decode(d_model, num_heads, ff_dim, rate)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(512, activation=\"relu\")\n",
    "        self.fc3 = layers.Dense(256, activation=\"relu\")\n",
    "        self.fc2 = layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        #x = x+self.PE\n",
    "        y = self.transformer_block(x)\n",
    "        x = self.transformer_block2(x,y,y)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.fc2(x)\n",
    "class TransformerBlock_decode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_decode, self).__init__()\n",
    "\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "    def call(self, inputs,q,k, training):\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        attn_output1=self.att(q, k,out1)\n",
    "        out2 = self.layernorm1(out1 + attn_output1)\n",
    "        ffn_output = self.ffn(out2)\n",
    "        return self.layernorm2(out2 + ffn_output)\n",
    "\n",
    "# Define the TransformerBlock layer\n",
    "class TransformerBlock_Encode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_Encode, self).__init__()\n",
    "        self.con= layers.Conv1D(256,5,padding='same')\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs=self.con(inputs)\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "# Define your data loading and preprocessing here\n",
    "# Example: X_train, y_train = load_data_and_preprocess()\n",
    "\n",
    "# Define the model\n",
    "input_vocab_size = 1024  # Replace with the actual vocabulary size\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "ff_dim = 256\n",
    "\n",
    "model = TransformerModel(input_vocab_size, d_model, num_heads, ff_dim)\n",
    "initial_learning_rate = 0.0001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=[\"accuracy\"])\n",
    "\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),tf.keras.callbacks.ModelCheckpoint(filepath='AMAP1.h5', monitor='val_accuracy', save_best_only=True,mode='auto',save_weights_only=True)]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train,y_train,epochs = 100,batch_size=32,validation_split=0.1,callbacks=[callback],verbose=1,shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8757728a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:55:19.179446Z",
     "iopub.status.busy": "2024-06-28T07:55:19.178805Z",
     "iopub.status.idle": "2024-06-28T07:55:19.596297Z",
     "shell.execute_reply": "2024-06-28T07:55:19.595522Z"
    },
    "id": "Bm5Vdbe-lVeT",
    "papermill": {
     "duration": 0.520183,
     "end_time": "2024-06-28T07:55:19.598574",
     "exception": false,
     "start_time": "2024-06-28T07:55:19.078391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights('/kaggle/input/amap/tensorflow2/model/1/AMAP1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6836df3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:55:19.798730Z",
     "iopub.status.busy": "2024-06-28T07:55:19.798411Z",
     "iopub.status.idle": "2024-06-28T07:55:19.802425Z",
     "shell.execute_reply": "2024-06-28T07:55:19.801615Z"
    },
    "id": "xHT6ycII_PcZ",
    "papermill": {
     "duration": 0.105939,
     "end_time": "2024-06-28T07:55:19.804306",
     "exception": false,
     "start_time": "2024-06-28T07:55:19.698367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efec9a66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:55:20.002777Z",
     "iopub.status.busy": "2024-06-28T07:55:20.002504Z",
     "iopub.status.idle": "2024-06-28T07:56:13.175279Z",
     "shell.execute_reply": "2024-06-28T07:56:13.174221Z"
    },
    "id": "Ep5tIGliLqWA",
    "outputId": "a2379bb7-f2ff-455a-f8ec-d3c0f7c51fba",
    "papermill": {
     "duration": 53.275062,
     "end_time": "2024-06-28T07:56:13.177686",
     "exception": false,
     "start_time": "2024-06-28T07:55:19.902624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 3s 14ms/step\n",
      "combined train datasets\n",
      "deep learning: Accuracy 97.54%\n",
      "deep learning: Precision-Recall 95.46%\n",
      "deep learning: Matthews Coefficient 94.96%\n",
      "deep learning: Cohen Kappa Score 94.96%\n",
      "deep learning: F1-Score 97.08%\n",
      "deep learning: AUC Score 99.46%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.98      0.98      0.98      3332\n",
      "      high 1       0.97      0.97      0.97      2411\n",
      "\n",
      "    accuracy                           0.98      5743\n",
      "   macro avg       0.97      0.97      0.97      5743\n",
      "weighted avg       0.98      0.98      0.98      5743\n",
      "\n",
      "combined test datasets\n",
      "45/45 [==============================] - 1s 14ms/step\n",
      "deep learning: Accuracy 89.28%\n",
      "deep learning: Precision 87.59%\n",
      "deep learning: Recall 86.41%\n",
      "deep learning: Matthews Coefficient 77.88%\n",
      "deep learning: Cohen Kappa Score 77.87%\n",
      "deep learning: F1-Score 86.99%\n",
      "deep learning: AUC Score 94.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.90      0.91      0.91       840\n",
      "      high 1       0.88      0.86      0.87       596\n",
      "\n",
      "    accuracy                           0.89      1436\n",
      "   macro avg       0.89      0.89      0.89      1436\n",
      "weighted avg       0.89      0.89      0.89      1436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "y_pred=model.predict(X_train)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred, pos_label=1)\n",
    "auc=metrics.auc(fpr, tpr)\n",
    "\n",
    "y_pred[y_pred>0.5]=1\n",
    "y_pred[y_pred<0.5]=0\n",
    "\n",
    "cv_preds = y_pred\n",
    "print('combined train datasets')\n",
    "name='deep learning'\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_train, cv_preds)))\n",
    "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_train, cv_preds)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_train, cv_preds)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_train, cv_preds)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_train, cv_preds)))\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_train, cv_preds, target_names=target_names))\n",
    "\n",
    "# Predictions Validation Set\n",
    "print('combined test datasets')\n",
    "y_pred2=model.predict(X_test)\n",
    "l=np.zeros(len(y_pred2))\n",
    "l=l.reshape(-1,1)\n",
    "l[y_pred2>=0.5]=1\n",
    "l[y_pred2<0.5]=0\n",
    "cv_preds2 = l\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_test, cv_preds2)))\n",
    "print(\"%s: Precision %0.2f%%\" % (name, 100*metrics.precision_score(y_test, cv_preds2)))\n",
    "print(\"%s: Recall %0.2f%%\" % (name, 100*metrics.recall_score(y_test, cv_preds2)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_test, cv_preds2)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_test, cv_preds2)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_test, cv_preds2)))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred2, pos_label=1)\n",
    "auc=metrics.auc(fpr, tpr)\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_test, cv_preds2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43c8c49d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:56:13.391957Z",
     "iopub.status.busy": "2024-06-28T07:56:13.391358Z",
     "iopub.status.idle": "2024-06-28T07:56:13.406852Z",
     "shell.execute_reply": "2024-06-28T07:56:13.406139Z"
    },
    "id": "qs4nHEvx-SI3",
    "papermill": {
     "duration": 0.122671,
     "end_time": "2024-06-28T07:56:13.408614",
     "exception": false,
     "start_time": "2024-06-28T07:56:13.285943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnnamp_model = pd.read_csv('/kaggle/input/hemolytic/hlppredfuse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c434b890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:56:13.618706Z",
     "iopub.status.busy": "2024-06-28T07:56:13.618418Z",
     "iopub.status.idle": "2024-06-28T07:56:13.622969Z",
     "shell.execute_reply": "2024-06-28T07:56:13.622143Z"
    },
    "id": "XlB6biA8-SI-",
    "papermill": {
     "duration": 0.112637,
     "end_time": "2024-06-28T07:56:13.624835",
     "exception": false,
     "start_time": "2024-06-28T07:56:13.512198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=rnnamp_model['text']\n",
    "y=np.array(rnnamp_model['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b11ce35d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:56:13.833056Z",
     "iopub.status.busy": "2024-06-28T07:56:13.832397Z",
     "iopub.status.idle": "2024-06-28T07:56:13.838386Z",
     "shell.execute_reply": "2024-06-28T07:56:13.837479Z"
    },
    "id": "f5fFAg1x-SI-",
    "papermill": {
     "duration": 0.111618,
     "end_time": "2024-06-28T07:56:13.840228",
     "exception": false,
     "start_time": "2024-06-28T07:56:13.728610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74d4a058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:56:14.047464Z",
     "iopub.status.busy": "2024-06-28T07:56:14.047173Z",
     "iopub.status.idle": "2024-06-28T07:56:14.051280Z",
     "shell.execute_reply": "2024-06-28T07:56:14.050564Z"
    },
    "id": "_0LgRfEY-SI_",
    "papermill": {
     "duration": 0.109747,
     "end_time": "2024-06-28T07:56:14.053141",
     "exception": false,
     "start_time": "2024-06-28T07:56:13.943394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4af03f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:56:14.261674Z",
     "iopub.status.busy": "2024-06-28T07:56:14.261395Z",
     "iopub.status.idle": "2024-06-28T07:56:15.222838Z",
     "shell.execute_reply": "2024-06-28T07:56:15.221815Z"
    },
    "id": "kTXGBr65-SI_",
    "papermill": {
     "duration": 1.068649,
     "end_time": "2024-06-28T07:56:15.225206",
     "exception": false,
     "start_time": "2024-06-28T07:56:14.156557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizer(text,max_len):\n",
    "  #dic={'A':1,'G':1,'V':1,'I':2,'L':2,'F':2,'P':2,'Y':3,'M':3,'T':3,'S':3,'H':4,'N':4,'Q':4,'W':4,'K':5,'R':5,'D':6,'E':6,'C':7}\n",
    "  dic={'A':1,'G':2,'V':3,'I':4,'L':5,'F':6,'P':7,'Y':8,'M':9,'T':10,'S':11,'H':12,'N':13,'Q':14,'W':15,'K':16,'R':17,'D':18,'E':19,'C':20}\n",
    "  onehot=[]\n",
    "  t=[]\n",
    "  for i in range(len(text)):\n",
    "    row=[]\n",
    "    l=[]\n",
    "    char=text[i].split(' ')\n",
    "    for j in range(max_len):\n",
    "      if j< len(char):\n",
    "        row.append(dic[char[j]])\n",
    "        r=np.zeros(20)\n",
    "        r[dic[char[j]]-1]=1\n",
    "      else:\n",
    "        r=np.ones(20)*-1\n",
    "        row.append(0)\n",
    "      l.append(r)\n",
    "    l=np.array(l)\n",
    "    onehot.append(l)\n",
    "    t.append(row)\n",
    "  onehot=np.array(onehot)\n",
    "  t=np.array(t)\n",
    "  return t,onehot\n",
    "max_len=50\n",
    "X_train,onehot_train=tokenizer(X_train,max_len)\n",
    "X_test,onehot_test=tokenizer(X_test,max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc69b98d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:56:15.440081Z",
     "iopub.status.busy": "2024-06-28T07:56:15.439746Z",
     "iopub.status.idle": "2024-06-28T07:57:05.747110Z",
     "shell.execute_reply": "2024-06-28T07:57:05.746139Z"
    },
    "id": "4o7zagCK7eRH",
    "outputId": "6a276bf5-38a8-4d50-e9fa-e814e185bfd6",
    "papermill": {
     "duration": 50.41718,
     "end_time": "2024-06-28T07:57:05.749324",
     "exception": false,
     "start_time": "2024-06-28T07:56:15.332144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 12s 50ms/step - loss: 0.3653 - accuracy: 0.8337 - val_loss: 0.3332 - val_accuracy: 0.8759\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.1792 - accuracy: 0.9325 - val_loss: 0.2314 - val_accuracy: 0.9184\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.1163 - accuracy: 0.9585 - val_loss: 0.1472 - val_accuracy: 0.9468\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0760 - accuracy: 0.9775 - val_loss: 0.1568 - val_accuracy: 0.9433\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0531 - accuracy: 0.9842 - val_loss: 0.1689 - val_accuracy: 0.9433\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.1759 - val_accuracy: 0.9433\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0246 - accuracy: 0.9937 - val_loss: 0.1986 - val_accuracy: 0.9362\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0172 - accuracy: 0.9961 - val_loss: 0.2106 - val_accuracy: 0.9504\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.2110 - val_accuracy: 0.9433\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.2988 - val_accuracy: 0.9362\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.2480 - val_accuracy: 0.9433\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.2475 - val_accuracy: 0.9433\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9539\n"
     ]
    }
   ],
   "source": [
    "@register_keras_serializable()\n",
    "class TransformerModel(keras.Model):\n",
    "    def __init__(self, input_vocab_size, d_model, num_heads, ff_dim, rate=0.1, maxlen=50):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = layers.Embedding(input_vocab_size, d_model)\n",
    "        self.PE = positional_encoding(maxlen, d_model)\n",
    "        self.transformer_block = TransformerBlock_Encode(d_model, num_heads, ff_dim, rate)\n",
    "        self.transformer_block2 = TransformerBlock_decode(d_model, num_heads, ff_dim, rate)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(512, activation=\"relu\")\n",
    "        self.fc3 = layers.Dense(256, activation=\"relu\")\n",
    "        self.fc2 = layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        #x = x+self.PE\n",
    "        y = self.transformer_block(x)\n",
    "        x = self.transformer_block2(x,y,y)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.fc2(x)\n",
    "class TransformerBlock_decode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_decode, self).__init__()\n",
    "\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "    def call(self, inputs,q,k, training):\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        attn_output1=self.att(q, k,out1)\n",
    "        out2 = self.layernorm1(out1 + attn_output1)\n",
    "        ffn_output = self.ffn(out2)\n",
    "        return self.layernorm2(out2 + ffn_output)\n",
    "\n",
    "# Define the TransformerBlock layer\n",
    "class TransformerBlock_Encode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_Encode, self).__init__()\n",
    "        self.con= layers.Conv1D(256,5,padding='same')\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs=self.con(inputs)\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "# Define your data loading and preprocessing here\n",
    "# Example: X_train, y_train = load_data_and_preprocess()\n",
    "\n",
    "# Define the model\n",
    "input_vocab_size = 1024  # Replace with the actual vocabulary size\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "ff_dim = 256\n",
    "model2 = TransformerModel(input_vocab_size, d_model, num_heads, ff_dim)\n",
    "initial_learning_rate = 0.0001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "# Compile the model\n",
    "model2.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=[\"accuracy\"])\n",
    "\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),tf.keras.callbacks.ModelCheckpoint(filepath='AMAP2.h5', monitor='val_accuracy', save_best_only=True,mode='auto',save_weights_only=True)]\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(X_train,y_train,epochs = 100,batch_size=32,validation_split=0.1,callbacks=[callback],verbose=1,shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18f1ccf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:06.044024Z",
     "iopub.status.busy": "2024-06-28T07:57:06.043732Z",
     "iopub.status.idle": "2024-06-28T07:57:06.432291Z",
     "shell.execute_reply": "2024-06-28T07:57:06.431509Z"
    },
    "id": "oxPvpG1Z7m2v",
    "papermill": {
     "duration": 0.536919,
     "end_time": "2024-06-28T07:57:06.434552",
     "exception": false,
     "start_time": "2024-06-28T07:57:05.897633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.load_weights('/kaggle/input/amap/tensorflow2/model/1/AMAP2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b4d2c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:06.731122Z",
     "iopub.status.busy": "2024-06-28T07:57:06.730814Z",
     "iopub.status.idle": "2024-06-28T07:57:06.846773Z",
     "shell.execute_reply": "2024-06-28T07:57:06.845801Z"
    },
    "id": "k9NxcbR5Lh4f",
    "papermill": {
     "duration": 0.267212,
     "end_time": "2024-06-28T07:57:06.850484",
     "exception": false,
     "start_time": "2024-06-28T07:57:06.583272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.save_weights(\"AMAP2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe032b44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:07.150053Z",
     "iopub.status.busy": "2024-06-28T07:57:07.149720Z",
     "iopub.status.idle": "2024-06-28T07:57:09.355951Z",
     "shell.execute_reply": "2024-06-28T07:57:09.354897Z"
    },
    "id": "x71T_rAI7m2v",
    "outputId": "f5cf2956-e0fe-4936-dfdc-ec892cacb6d3",
    "papermill": {
     "duration": 2.355184,
     "end_time": "2024-06-28T07:57:09.358070",
     "exception": false,
     "start_time": "2024-06-28T07:57:07.002886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 15ms/step\n",
      "hlppredfuse train datasets\n",
      "deep learning: Accuracy 99.29%\n",
      "deep learning: Precision-Recall 98.29%\n",
      "deep learning: Matthews Coefficient 98.34%\n",
      "deep learning: Cohen Kappa Score 98.34%\n",
      "deep learning: F1-Score 98.85%\n",
      "deep learning: AUC Score 94.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.99      1.00      0.99      1938\n",
      "      high 1       1.00      0.98      0.99       876\n",
      "\n",
      "    accuracy                           0.99      2814\n",
      "   macro avg       0.99      0.99      0.99      2814\n",
      "weighted avg       0.99      0.99      0.99      2814\n",
      "\n",
      "hlppredfuse test datasets\n",
      "22/22 [==============================] - 0s 13ms/step\n",
      "deep learning: Accuracy 96.16%\n",
      "deep learning: Precision 93.27%\n",
      "deep learning: Recall 94.55%\n",
      "deep learning: Matthews Coefficient 91.11%\n",
      "deep learning: Cohen Kappa Score 91.11%\n",
      "deep learning: F1-Score 93.91%\n",
      "deep learning: AUC Score 97.64%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.98      0.97      0.97       484\n",
      "      high 1       0.93      0.95      0.94       220\n",
      "\n",
      "    accuracy                           0.96       704\n",
      "   macro avg       0.95      0.96      0.96       704\n",
      "weighted avg       0.96      0.96      0.96       704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "y_pred=model2.predict(X_train)\n",
    "y_pred[y_pred>0.5]=1\n",
    "y_pred[y_pred<0.5]=0\n",
    "\n",
    "cv_preds = y_pred\n",
    "print('hlppredfuse train datasets')\n",
    "name='deep learning'\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_train, cv_preds)))\n",
    "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_train, cv_preds)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_train, cv_preds)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_train, cv_preds)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_train, cv_preds)))\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_train, cv_preds, target_names=target_names))\n",
    "\n",
    "# Predictions Validation Set\n",
    "print('hlppredfuse test datasets')\n",
    "y_pred2=model2.predict(X_test)\n",
    "l=np.zeros(len(y_pred2))\n",
    "l=l.reshape(-1,1)\n",
    "l[y_pred2>=0.5]=1\n",
    "l[y_pred2<0.5]=0\n",
    "cv_preds2 = l\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_test, cv_preds2)))\n",
    "print(\"%s: Precision %0.2f%%\" % (name, 100*metrics.precision_score(y_test, cv_preds2)))\n",
    "print(\"%s: Recall %0.2f%%\" % (name, 100*metrics.recall_score(y_test, cv_preds2)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_test, cv_preds2)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_test, cv_preds2)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_test, cv_preds2)))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred2, pos_label=1)\n",
    "auc=metrics.auc(fpr, tpr)\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_test, cv_preds2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc690249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:09.667988Z",
     "iopub.status.busy": "2024-06-28T07:57:09.667664Z",
     "iopub.status.idle": "2024-06-28T07:57:09.681948Z",
     "shell.execute_reply": "2024-06-28T07:57:09.681090Z"
    },
    "id": "7kJr65zb-WtS",
    "papermill": {
     "duration": 0.168771,
     "end_time": "2024-06-28T07:57:09.683931",
     "exception": false,
     "start_time": "2024-06-28T07:57:09.515160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnnamp_model = pd.read_csv('/kaggle/input/hemolytic/rnnamp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f127094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:09.982398Z",
     "iopub.status.busy": "2024-06-28T07:57:09.982084Z",
     "iopub.status.idle": "2024-06-28T07:57:09.986810Z",
     "shell.execute_reply": "2024-06-28T07:57:09.985964Z"
    },
    "id": "WCgqgMiP-WtS",
    "papermill": {
     "duration": 0.155366,
     "end_time": "2024-06-28T07:57:09.988684",
     "exception": false,
     "start_time": "2024-06-28T07:57:09.833318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=rnnamp_model['text']\n",
    "y=np.array(rnnamp_model['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8b1e524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:10.288697Z",
     "iopub.status.busy": "2024-06-28T07:57:10.288419Z",
     "iopub.status.idle": "2024-06-28T07:57:10.294495Z",
     "shell.execute_reply": "2024-06-28T07:57:10.293562Z"
    },
    "id": "ia1ZGn2t-WtT",
    "papermill": {
     "duration": 0.157996,
     "end_time": "2024-06-28T07:57:10.296434",
     "exception": false,
     "start_time": "2024-06-28T07:57:10.138438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a4d38bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:10.607380Z",
     "iopub.status.busy": "2024-06-28T07:57:10.606898Z",
     "iopub.status.idle": "2024-06-28T07:57:10.611973Z",
     "shell.execute_reply": "2024-06-28T07:57:10.610896Z"
    },
    "id": "ZTPCKy2d-WtT",
    "papermill": {
     "duration": 0.169174,
     "end_time": "2024-06-28T07:57:10.615245",
     "exception": false,
     "start_time": "2024-06-28T07:57:10.446071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d07a7859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:10.957491Z",
     "iopub.status.busy": "2024-06-28T07:57:10.957097Z",
     "iopub.status.idle": "2024-06-28T07:57:11.708569Z",
     "shell.execute_reply": "2024-06-28T07:57:11.707549Z"
    },
    "id": "LfLheYBz-WtT",
    "papermill": {
     "duration": 0.929744,
     "end_time": "2024-06-28T07:57:11.710878",
     "exception": false,
     "start_time": "2024-06-28T07:57:10.781134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizer(text,max_len):\n",
    "  #dic={'A':1,'G':1,'V':1,'I':2,'L':2,'F':2,'P':2,'Y':3,'M':3,'T':3,'S':3,'H':4,'N':4,'Q':4,'W':4,'K':5,'R':5,'D':6,'E':6,'C':7}\n",
    "  dic={'A':1,'G':2,'V':3,'I':4,'L':5,'F':6,'P':7,'Y':8,'M':9,'T':10,'S':11,'H':12,'N':13,'Q':14,'W':15,'K':16,'R':17,'D':18,'E':19,'C':20}\n",
    "  onehot=[]\n",
    "  t=[]\n",
    "  for i in range(len(text)):\n",
    "    row=[]\n",
    "    l=[]\n",
    "    char=text[i].split(' ')\n",
    "    for j in range(max_len):\n",
    "      if j< len(char):\n",
    "        row.append(dic[char[j]])\n",
    "        r=np.zeros(20)\n",
    "        r[dic[char[j]]-1]=1\n",
    "      else:\n",
    "        r=np.ones(20)*-1\n",
    "        row.append(0)\n",
    "      l.append(r)\n",
    "    l=np.array(l)\n",
    "    onehot.append(l)\n",
    "    t.append(row)\n",
    "  onehot=np.array(onehot)\n",
    "  t=np.array(t)\n",
    "  return t,onehot\n",
    "max_len=50\n",
    "X_train,onehot_train=tokenizer(X_train,max_len)\n",
    "X_test,onehot_test=tokenizer(X_test,max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4aa2f450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:12.053446Z",
     "iopub.status.busy": "2024-06-28T07:57:12.052724Z",
     "iopub.status.idle": "2024-06-28T07:57:57.098644Z",
     "shell.execute_reply": "2024-06-28T07:57:57.097522Z"
    },
    "id": "wW0hCzH7-tEN",
    "outputId": "ece7fe92-0345-42bd-e68f-6682a7e7d5d8",
    "papermill": {
     "duration": 45.24071,
     "end_time": "2024-06-28T07:57:57.100815",
     "exception": false,
     "start_time": "2024-06-28T07:57:11.860105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 10s 52ms/step - loss: 0.6498 - accuracy: 0.6391 - val_loss: 0.6174 - val_accuracy: 0.7073\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 2s 40ms/step - loss: 0.4863 - accuracy: 0.7712 - val_loss: 0.5893 - val_accuracy: 0.7463\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 2s 40ms/step - loss: 0.3930 - accuracy: 0.8283 - val_loss: 0.5424 - val_accuracy: 0.7561\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 2s 38ms/step - loss: 0.3517 - accuracy: 0.8549 - val_loss: 0.5767 - val_accuracy: 0.7512\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 0.3078 - accuracy: 0.8837 - val_loss: 0.5513 - val_accuracy: 0.7610\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 0.2687 - accuracy: 0.8995 - val_loss: 0.5076 - val_accuracy: 0.7902\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 2s 38ms/step - loss: 0.2421 - accuracy: 0.9114 - val_loss: 0.5651 - val_accuracy: 0.7756\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.2131 - accuracy: 0.9234 - val_loss: 0.5231 - val_accuracy: 0.7659\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.1776 - accuracy: 0.9375 - val_loss: 0.5561 - val_accuracy: 0.7854\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.1651 - accuracy: 0.9408 - val_loss: 0.6013 - val_accuracy: 0.7366\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 0.1392 - accuracy: 0.9511 - val_loss: 0.5754 - val_accuracy: 0.7659\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.1180 - accuracy: 0.9592 - val_loss: 0.5771 - val_accuracy: 0.7805\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.1079 - accuracy: 0.9641 - val_loss: 0.6510 - val_accuracy: 0.7707\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.1011 - accuracy: 0.9658 - val_loss: 0.6913 - val_accuracy: 0.7561\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.0997 - accuracy: 0.9674 - val_loss: 0.6024 - val_accuracy: 0.7805\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 0.0785 - accuracy: 0.9755 - val_loss: 0.6469 - val_accuracy: 0.7951\n"
     ]
    }
   ],
   "source": [
    "# Define the Transformer model\n",
    "@register_keras_serializable()\n",
    "class TransformerModel(keras.Model):\n",
    "    def __init__(self, input_vocab_size, d_model, num_heads, ff_dim, rate=0.1, maxlen=50):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = layers.Embedding(input_vocab_size, d_model)\n",
    "        self.PE = positional_encoding(maxlen, d_model)\n",
    "        self.transformer_block = TransformerBlock_Encode(d_model, num_heads, ff_dim, rate)\n",
    "        self.transformer_block2 = TransformerBlock_decode(d_model, num_heads, ff_dim, rate)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(512, activation=\"relu\")\n",
    "        self.fc3 = layers.Dense(256, activation=\"relu\")\n",
    "        self.fc2 = layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        #x = x+self.PE\n",
    "        y = self.transformer_block(x)\n",
    "        x = self.transformer_block2(x,y,y)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.fc2(x)\n",
    "class TransformerBlock_decode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_decode, self).__init__()\n",
    "\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "    def call(self, inputs,q,k, training):\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        attn_output1=self.att(q, k,out1)\n",
    "        out2 = self.layernorm1(out1 + attn_output1)\n",
    "        ffn_output = self.ffn(out2)\n",
    "        return self.layernorm2(out2 + ffn_output)\n",
    "\n",
    "# Define the TransformerBlock layer\n",
    "class TransformerBlock_Encode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_Encode, self).__init__()\n",
    "        self.con= layers.Conv1D(256,5,padding='same')\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs=self.con(inputs)\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "# Define your data loading and preprocessing here\n",
    "# Example: X_train, y_train = load_data_and_preprocess()\n",
    "\n",
    "# Define the model\n",
    "input_vocab_size = 1024  # Replace with the actual vocabulary size\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "ff_dim = 256\n",
    "model3 = TransformerModel(input_vocab_size, d_model, num_heads, ff_dim)\n",
    "initial_learning_rate = 0.0001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "# Compile the model\n",
    "model3.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=[\"accuracy\"])\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),tf.keras.callbacks.ModelCheckpoint(filepath='AMAP3.h5', monitor='val_accuracy', save_best_only=True,mode='auto',save_weights_only=True)]\n",
    "\n",
    "# Train the model\n",
    "history = model3.fit(X_train,y_train,epochs = 100,batch_size=32,validation_split=0.1,callbacks=[callback],verbose=1,shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4e3b10c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:57.478674Z",
     "iopub.status.busy": "2024-06-28T07:57:57.477957Z",
     "iopub.status.idle": "2024-06-28T07:57:57.912860Z",
     "shell.execute_reply": "2024-06-28T07:57:57.912063Z"
    },
    "id": "_hKa8EZ9-tEU",
    "papermill": {
     "duration": 0.62493,
     "end_time": "2024-06-28T07:57:57.915056",
     "exception": false,
     "start_time": "2024-06-28T07:57:57.290126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3.load_weights('/kaggle/input/amap/tensorflow2/model/1/AMAP3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a84162c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:57:58.293852Z",
     "iopub.status.busy": "2024-06-28T07:57:58.293030Z",
     "iopub.status.idle": "2024-06-28T07:58:00.080679Z",
     "shell.execute_reply": "2024-06-28T07:58:00.079706Z"
    },
    "id": "ZBAhB9ww-tEV",
    "papermill": {
     "duration": 1.981022,
     "end_time": "2024-06-28T07:58:00.082740",
     "exception": false,
     "start_time": "2024-06-28T07:57:58.101718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 15ms/step\n",
      "rnnamp train datasets\n",
      "deep learning: Accuracy 94.96%\n",
      "deep learning: Precision-Recall 93.30%\n",
      "deep learning: Matthews Coefficient 89.88%\n",
      "deep learning: Cohen Kappa Score 89.88%\n",
      "deep learning: F1-Score 95.29%\n",
      "deep learning: AUC Score 97.64%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.95      0.95      0.95       952\n",
      "      high 1       0.95      0.95      0.95      1093\n",
      "\n",
      "    accuracy                           0.95      2045\n",
      "   macro avg       0.95      0.95      0.95      2045\n",
      "weighted avg       0.95      0.95      0.95      2045\n",
      "\n",
      "rnnamp test datasets\n",
      "16/16 [==============================] - 0s 13ms/step\n",
      "deep learning: Accuracy 79.69%\n",
      "deep learning: Precision 82.93%\n",
      "deep learning: Recall 76.69%\n",
      "deep learning: Matthews Coefficient 59.62%\n",
      "deep learning: Cohen Kappa Score 59.44%\n",
      "deep learning: F1-Score 79.69%\n",
      "deep learning: AUC Score 86.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.77      0.83      0.80       246\n",
      "      high 1       0.83      0.77      0.80       266\n",
      "\n",
      "    accuracy                           0.80       512\n",
      "   macro avg       0.80      0.80      0.80       512\n",
      "weighted avg       0.80      0.80      0.80       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "y_pred=model3.predict(X_train)\n",
    "y_pred[y_pred>0.5]=1\n",
    "y_pred[y_pred<0.5]=0\n",
    "\n",
    "cv_preds = y_pred\n",
    "print('rnnamp train datasets')\n",
    "name='deep learning'\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_train, cv_preds)))\n",
    "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_train, cv_preds)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_train, cv_preds)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_train, cv_preds)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_train, cv_preds)))\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_train, cv_preds, target_names=target_names))\n",
    "\n",
    "# Predictions Validation Set\n",
    "print('rnnamp test datasets')\n",
    "y_pred2=model3.predict(X_test)\n",
    "l=np.zeros(len(y_pred2))\n",
    "l=l.reshape(-1,1)\n",
    "l[y_pred2>=0.5]=1\n",
    "l[y_pred2<0.5]=0\n",
    "cv_preds2 = l\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_test, cv_preds2)))\n",
    "print(\"%s: Precision %0.2f%%\" % (name, 100*metrics.precision_score(y_test, cv_preds2)))\n",
    "print(\"%s: Recall %0.2f%%\" % (name, 100*metrics.recall_score(y_test, cv_preds2)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_test, cv_preds2)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_test, cv_preds2)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_test, cv_preds2)))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred2, pos_label=1)\n",
    "auc=metrics.auc(fpr, tpr)\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_test, cv_preds2, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7536865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:58:00.467417Z",
     "iopub.status.busy": "2024-06-28T07:58:00.466667Z",
     "iopub.status.idle": "2024-06-28T07:58:00.588009Z",
     "shell.execute_reply": "2024-06-28T07:58:00.586972Z"
    },
    "id": "k9NxcbR5Lh4f",
    "papermill": {
     "duration": 0.313216,
     "end_time": "2024-06-28T07:58:00.590446",
     "exception": false,
     "start_time": "2024-06-28T07:58:00.277230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3.save_weights(\"AMAP3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b0633",
   "metadata": {
    "papermill": {
     "duration": 0.207386,
     "end_time": "2024-06-28T07:58:00.991239",
     "exception": false,
     "start_time": "2024-06-28T07:58:00.783853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4241668,
     "sourceId": 7325770,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 37191,
     "sourceId": 44279,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 279.687869,
   "end_time": "2024-06-28T07:58:03.615916",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-28T07:53:23.928047",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
